{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5042/5042 [00:05<00:00, 920.75 examples/s]\n",
      "Map: 100%|██████████| 565/565 [00:00<00:00, 663.53 examples/s]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\seraf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 28/28 [00:00<00:00, 98.41 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 28\n",
      "})\n",
      "Printing examples...\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'my_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 231\u001b[0m\n\u001b[0;32m    229\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(checkpoint_fp, map_location\u001b[38;5;241m=\u001b[39mdevice) \n\u001b[0;32m    230\u001b[0m Checkpoint\u001b[38;5;241m.\u001b[39mload_objects(to_load\u001b[38;5;241m=\u001b[39mto_save, checkpoint\u001b[38;5;241m=\u001b[39mcheckpoint)\n\u001b[1;32m--> 231\u001b[0m \u001b[43mprint_pred_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;66;03m# Define model output\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_output\u001b[39m(inputs):\n",
      "Cell \u001b[1;32mIn[16], line 119\u001b[0m, in \u001b[0;36mprint_pred_summary\u001b[1;34m(model, df)\u001b[0m\n\u001b[0;32m    117\u001b[0m y_true_flat \u001b[38;5;241m=\u001b[39m [item\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m y_true \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sublist]\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(y_true):\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00melement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmy_list\u001b[38;5;241m.\u001b[39mcount(element)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    120\u001b[0m acc_score \u001b[38;5;241m=\u001b[39m accuracy_score(y_true_flat, y_pred_flat)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAcc score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, acc_score)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'my_list' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPTNeoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from sklearn.preprocessing import normalize\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ignite.contrib.handlers import PiecewiseLinear\n",
    "from transformers import AdamW\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.metrics import Accuracy\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from ignite.metrics import Precision, Recall\n",
    "from ignite.handlers import Checkpoint, global_step_from_engine\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "from captum.attr import visualization as viz\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", device)\n",
    "USE_CHECKPOINT = True\n",
    "\n",
    "def save_plot(arr, lbl):\n",
    "    x = np.arange(len(arr))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(x, arr, label='Data') \n",
    "    plt.title(lbl)  \n",
    "    plt.xlabel('X-axis') \n",
    "    plt.ylabel('Y-axis') \n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot to an image file (e.g., PNG)\n",
    "    plt.savefig(f\"{lbl}.png\")\n",
    "    \n",
    "def read_data():\n",
    "    data = pd.read_csv(\"posts.csv\", delimiter=\",\", dtype={'target': int})\n",
    "\n",
    "    data['combined'] = data['title'] + \" \" + data['text']\n",
    "\n",
    "    # data, _ = train_test_split(data, test_size=0.9)               # when testing the code, use this line to do a sanity check on 10% of data\n",
    "    train_data, test_data = train_test_split(data, test_size=0.1)\n",
    "\n",
    "    X_train = train_data['combined']\n",
    "    y_train = train_data['target']\n",
    "    X_test = test_data['combined']\n",
    "    y_test = test_data['target']\n",
    "\n",
    "\n",
    "    X_train = X_train.dropna()\n",
    "    y_train = y_train[X_train.index]  # Ensure y_train matches X_train\n",
    "\n",
    "    X_test = X_test.dropna()\n",
    "    y_test = y_test[X_test.index]  # Ensure y_test matches X_test\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    return tokenizer(examples[\"combined\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "def parse_dataset(df):\n",
    "    df = df.dropna()\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "    dataset = dataset.map(tokenize_function, batched=True)\n",
    "    dataset = dataset.remove_columns(['title', 'text', 'Unnamed: 0', '__index_level_0__', 'combined'])\n",
    "    dataset = dataset.rename_column(\"target\", \"labels\")\n",
    "    dataset.set_format(\"torch\")\n",
    "    return dataset\n",
    "\n",
    "def df_to_dataloader():\n",
    "\n",
    "    dataset = pd.read_csv(\"posts.csv\", delimiter=\",\", dtype={'target': int})\n",
    "    dataset['combined'] = dataset['title'] + \" \" + dataset['text']\n",
    "\n",
    "    train_df, test_df = train_test_split(dataset, test_size=0.1, random_state=42)\n",
    "\n",
    "    tokenized_train = parse_dataset(train_df)\n",
    "    tokenized_test = parse_dataset(test_df)\n",
    "\n",
    "    train_dataloader = DataLoader(tokenized_train, shuffle=True, batch_size=32)\n",
    "    eval_dataloader = DataLoader(tokenized_test, batch_size=32)\n",
    "\n",
    "    return train_dataloader, eval_dataloader, train_df, test_df\n",
    "\n",
    "def print_pred_summary(model, df):\n",
    "    tokenized = parse_dataset(df)\n",
    "    print(tokenized)\n",
    "    loader = DataLoader(tokenized, batch_size = 16)\n",
    "    print(\"Printing examples...\")\n",
    "    acc = []\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    i = 0\n",
    "    for batch in loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        y_pred.append(predictions)\n",
    "        y_true.append(batch['labels'])\n",
    "        i += 1\n",
    "        print(i)\n",
    "\n",
    "    print(y_pred)\n",
    "    print(y_true)\n",
    "    y_pred_flat = [item.item() for sublist in y_pred for item in sublist]\n",
    "    y_true_flat = [item.item() for sublist in y_true for item in sublist]\n",
    "\n",
    "    acc_score = accuracy_score(y_true_flat, y_pred_flat)\n",
    "    print(\"Acc score:\", acc_score)\n",
    "\n",
    "    cm = confusion_matrix(y_true_flat, y_pred_flat, labels=[0, 1, 2, 3])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[0, 1, 2, 3])\n",
    "    disp.plot()\n",
    "    plt.savefig('conf_mat2.png')\n",
    "    \n",
    "        \n",
    "\n",
    "train_dataloader, eval_dataloader, train_df, test_df = df_to_dataloader()\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=5, problem_type=\"single_label_classification\")\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 12\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "milestones_values = [\n",
    "        (0, 5e-5),\n",
    "        (num_training_steps, 0.0),\n",
    "    ]\n",
    "lr_scheduler = PiecewiseLinear(\n",
    "        optimizer, param_name=\"lr\", milestones_values=milestones_values\n",
    "    )\n",
    "\n",
    "device = torch.device(\"cpu\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for param in model.distilbert.parameters():\n",
    "   param.requires_grad = False\n",
    "\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "def train_step(engine, batch):\n",
    "    model.train()\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    outputs = model(**batch)\n",
    "    \n",
    "    loss = outputs.loss\n",
    "    #loss = (loss * class_weights).mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    loss_values.append(loss.item())\n",
    "    return loss\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "\n",
    "trainer.add_event_handler(Events.ITERATION_STARTED, lr_scheduler)\n",
    "\n",
    "\n",
    "pbar = ProgressBar()\n",
    "\n",
    "pbar.attach(trainer)\n",
    "\n",
    "def evaluate_step(engine, batch):\n",
    "    model.eval()\n",
    "\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    print(\"ACC:\")\n",
    "    acc = []\n",
    "    print(accuracy_score(predictions, batch[\"labels\"]))\n",
    "   # print(precision_recall_fscore_support(predictions, batch[\"labels\"]))\n",
    "    return {'y_pred': predictions, 'y': batch[\"labels\"]}\n",
    "\n",
    "train_evaluator = Engine(evaluate_step)\n",
    "validation_evaluator = Engine(evaluate_step)\n",
    "\n",
    "to_save = {'model': model, 'optimizer': optimizer, 'trainer': trainer}\n",
    "checkpoint_dir = \"checkpoints_distilbert2/\"\n",
    "\n",
    "checkpoint = Checkpoint(\n",
    " \t to_save,\n",
    "    checkpoint_dir,\n",
    "    n_saved=1,\n",
    "   global_step_transform=global_step_from_engine(trainer),\n",
    ")  \n",
    "train_evaluator.add_event_handler(Events.COMPLETED, checkpoint)\n",
    "\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    if engine.state.epoch % 2 == 0:\n",
    "        train_evaluator.run(train_dataloader)\n",
    "        metrics = train_evaluator.state.metrics\n",
    "        print(f\"Training Results - Epoch: {engine.state.epoch}  \")\n",
    "\n",
    "def log_validation_results(engine):\n",
    "    if engine.state.epoch % 2 == 0:\n",
    "        validation_evaluator.run(eval_dataloader)\n",
    "        metrics = validation_evaluator.state.metrics\n",
    "        print(f\"Validation Results - Epoch: {engine.state.epoch}\")\n",
    "\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, log_validation_results)\n",
    "\n",
    "model.to(device)\n",
    "if USE_CHECKPOINT == True:\n",
    "    checkpoint_fp = './checkpoints_distilbert/' + \"checkpoint_4.pt\"\n",
    "    checkpoint = torch.load(checkpoint_fp, map_location=device) \n",
    "    Checkpoint.load_objects(to_load=to_save, checkpoint=checkpoint)\n",
    "    print_pred_summary(model, test_df)\n",
    "        # Define model output\n",
    "    def model_output(inputs):\n",
    "        return model(inputs)[0]\n",
    "\n",
    "    # Define model input\n",
    "    model_input = model.distilbert.embeddings\n",
    "    lig = LayerIntegratedGradients(model_output, model_input)\n",
    "\n",
    "    def construct_input_and_baseline(text):\n",
    "        max_length = 510\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "        baseline_token_id = tokenizer.pad_token_id \n",
    "        sep_token_id = tokenizer.sep_token_id \n",
    "        cls_token_id = tokenizer.cls_token_id \n",
    "\n",
    "        text_ids = tokenizer.encode(text, max_length=max_length, truncation=True, add_special_tokens=False)\n",
    "    \n",
    "        input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
    "        token_list = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "        baseline_input_ids = [cls_token_id] + [baseline_token_id] * len(text_ids) + [sep_token_id]\n",
    "        return torch.tensor([input_ids], device='cpu'), torch.tensor([baseline_input_ids], device='cpu'), token_list\n",
    "\n",
    "    text = 'This movie is superb'\n",
    "    input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
    "\n",
    "    print(f'original text: {input_ids}')\n",
    "    print(f'baseline text: {baseline_input_ids}')\n",
    "\n",
    "    def summarize_attributions(attributions):\n",
    "        attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "        attributions = attributions / torch.norm(attributions)\n",
    "        \n",
    "        return attributions\n",
    "\n",
    "    def interpret_text(text, true_class):\n",
    "        input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
    "        attributions, delta = lig.attribute(inputs= input_ids,\n",
    "                                        baselines= baseline_input_ids,\n",
    "                                        return_convergence_delta=True,\n",
    "                                        target=torch.tensor(true_class)\n",
    "                                        )\n",
    "        attributions_sum = summarize_attributions(attributions)\n",
    "\n",
    "        score_vis = viz.VisualizationDataRecord(\n",
    "                            word_attributions = attributions_sum,\n",
    "                            pred_prob = torch.max(model(input_ids)[0]),\n",
    "                            pred_class = torch.argmax(model(input_ids)[0]).numpy(),\n",
    "                            true_class = true_class,\n",
    "                            attr_class = text,\n",
    "                            attr_score = attributions_sum.sum(),       \n",
    "                            raw_input_ids = all_tokens,\n",
    "                            convergence_score = delta)\n",
    "\n",
    "        # if true_class != torch.argmax(model(input_ids)[0]).numpy():\n",
    "        #     return -10\n",
    "        # else:\n",
    "        #     return attributions_sum.sum()\n",
    "        display(HTML(viz.visualize_text([score_vis])))\n",
    "\n",
    "    # max_sm = 0\n",
    "    # max_i = 0\n",
    "    # for i in range(0, 20):\n",
    "    example = 15\n",
    "    train_df = train_df.dropna()\n",
    "    text = train_df['combined'].iloc[example]\n",
    "    true_class = train_df['target'].iloc[example]\n",
    "    print(text)\n",
    "    print(true_class)\n",
    "\n",
    "    interpret_text(text, true_class)\n",
    "        #print(sm)\n",
    "\n",
    "else:\n",
    "    trainer.run(train_dataloader, max_epochs=num_epochs)\n",
    "\n",
    "    save_plot(loss_values, 'Loss')\n",
    "    save_plot(train_acc, 'train')\n",
    "    save_plot(val_acc, 'val')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
